{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V100",
   "authorship_tag": "ABX9TyOvEU5j/7BOJrcPMKh2/4j6",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/haifeng-jin/keras-benchmarking/blob/main/batch_norm_op_torch_before.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "See details in [this pull request](https://github.com/keras-team/keras/pull/18793).\n",
    "\n",
    "This notebook runs on the base commit of the PR.\n",
    "\n",
    "Runtime: V100"
   ],
   "metadata": {
    "id": "HQsHTewXKNiz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uJM7dw0-kUyl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aadefaaa-a399-453a-af7b-43a58aca4c60"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following additional packages will be installed:\n",
      "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
      "The following NEW packages will be installed:\n",
      "  python3-pip-whl python3-setuptools-whl python3-venv python3.10-venv\n",
      "0 upgraded, 4 newly installed, 0 to remove and 9 not upgraded.\n",
      "Need to get 2,474 kB of archives.\n",
      "After this operation, 2,890 kB of additional disk space will be used.\n",
      "Selecting previously unselected package python3-pip-whl.\n",
      "(Reading database ... 120880 files and directories currently installed.)\n",
      "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
      "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
      "Selecting previously unselected package python3-setuptools-whl.\n",
      "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package python3.10-venv.\n",
      "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.2_amd64.deb ...\n",
      "Unpacking python3.10-venv (3.10.12-1~22.04.2) ...\n",
      "Selecting previously unselected package python3-venv.\n",
      "Preparing to unpack .../python3-venv_3.10.6-1~22.04_amd64.deb ...\n",
      "Unpacking python3-venv (3.10.6-1~22.04) ...\n",
      "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
      "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
      "Setting up python3.10-venv (3.10.12-1~22.04.2) ...\n",
      "Setting up python3-venv (3.10.6-1~22.04) ...\n",
      "Note: switching to '66bb075f765e0c7fe80bf7af6d3cbb9148824675'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 66bb075f7 Update example\n",
      "2023-11-20 19:34:19.847978: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 19:34:19.848040: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 19:34:19.848077: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 19:34:19.856355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 19:34:20.910694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "!apt install -qq python3-venv\n",
    "!pip install -q namex\n",
    "!git clone --quiet https://github.com/haifeng-jin/keras.git\n",
    "!cd keras && git checkout 66bb075f765e0c7fe80bf7af6d3cbb9148824675\n",
    "!python keras/pip_build.py --install > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "metadata": {
    "id": "b2q8oY1-ZHfH"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "keras.config.set_image_data_format(\"channels_first\")\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "class BenchmarkMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, start_batch=1, stop_batch=None):\n",
    "        self.start_batch = start_batch\n",
    "        self.stop_batch = stop_batch\n",
    "\n",
    "        self.state = {}\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if batch == self.start_batch:\n",
    "            self.state[\"benchmark_begin\"] = time.time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch == self.stop_batch:\n",
    "            self.state[\"benchmark_end\"] = time.time()\n",
    "            throughput = (self.stop_batch - self.start_batch + 1) / (\n",
    "                self.state[\"benchmark_end\"] - self.state[\"benchmark_begin\"]\n",
    "            )\n",
    "            self.state[\"throughput\"] = throughput\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        if batch == self.start_batch:\n",
    "            self.state[\"benchmark_begin\"] = time.time()\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        if batch == self.stop_batch:\n",
    "            self.state[\"benchmark_end\"] = time.time()\n",
    "            throughput = (self.stop_batch - self.start_batch + 1) / (\n",
    "                self.state[\"benchmark_end\"] - self.state[\"benchmark_begin\"]\n",
    "            )\n",
    "            self.state[\"throughput\"] = throughput\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "steps = 101\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.images = np.random.randn(3, 224, 224)\n",
    "        self.labels = np.random.randint(\n",
    "            0,\n",
    "            1000,\n",
    "            size=tuple(),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return steps * batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images, self.labels\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.DataLoader(\n",
    "    MyDataset(), batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# Prepare the model\n",
    "model = keras.applications.resnet50.ResNet50()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "callback = BenchmarkMetricsCallback(stop_batch=100)\n",
    "model.fit(dataset, epochs=1, callbacks=[callback])\n",
    "print(f\"training: {1000.0 / callback.state['throughput']:.0f} ms/step\")\n",
    "\n",
    "callback = BenchmarkMetricsCallback(stop_batch=100)\n",
    "model.predict(dataset, callbacks=[callback])\n",
    "print(f\"inferencing: {1000.0 / callback.state['throughput']:.0f} ms/step\")\n",
    "\n",
    "print(f\"Memory usages: {torch.cuda.memory_allocated() / 1024 / 1024} MB\")"
   ],
   "metadata": {
    "id": "uLrb3Rdp7GQY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ec6c7b75-5009-412e-9329-a6c98b4742d6"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 397ms/step - loss: 0.5964\n",
      "training: 397 ms/step\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step\n",
      "inferencing: 141 ms/step\n",
      "Memory usages: 414.5419921875 MB\n"
     ]
    }
   ]
  }
 ]
}